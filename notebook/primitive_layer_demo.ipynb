{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2cff567",
   "metadata": {},
   "source": [
    "1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59374e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498fa61",
   "metadata": {},
   "source": [
    "2. Clone repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672cb39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/cocooda/JEPAPrimitiveLayer.git\n",
    "%cd JEPAPrimitiveLayer\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/JEPAPrimitiveLayer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b71183",
   "metadata": {},
   "source": [
    "3. Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b39dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ------------------ Import config from repo ------------------\n",
    "from config import EMBED_DIM, PATCH_SIZE, IMAGE_H, IMAGE_W, TOKEN_DIM, ACTION_DIM, MASK_RATIO, VICREG_WEIGHT, DRIFT_WEIGHT, JEPA_WEIGHT, EMA_DECAY, BATCH_SIZE, NUM_STEPS, LR, DEVICE, DATA_ROOT\n",
    "\n",
    "# Your modules\n",
    "from utils.dataset import DrivingSceneDataset\n",
    "from utils.patch_utils import unpatchify\n",
    "from models.primitive_layer import PrimitiveLayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a432377",
   "metadata": {},
   "source": [
    "4. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46aeb1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/kaggle/input/test1t/exported_maps\"\n",
    "dataset = DrivingSceneDataset(DATA_ROOT)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "print(f\"Loaded {len(dataset)} samples from {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ebf39",
   "metadata": {},
   "source": [
    "5. Initialize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00c582",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = PrimitiveLayer(patch_size=PATCH_SIZE).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc2d9a",
   "metadata": {},
   "source": [
    "6. Check if checkpoints exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f50f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"/kaggle/working/checkpoints\", exist_ok=True)\n",
    "ckpt_path = \"/kaggle/working/checkpoints/primitive_layer.pth\"\n",
    "\n",
    "if os.path.exists(ckpt_path):\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    model.eval()\n",
    "    print(f\"Checkpoint loaded from {ckpt_path}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Training from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea821351",
   "metadata": {},
   "source": [
    "7. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab1596",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "for step, (frames, kin) in enumerate(loader):\n",
    "    if step >= NUM_STEPS:\n",
    "        break\n",
    "    frames, kin = frames.to(DEVICE), kin.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    _, total_loss, loss_dict = model(frames, kin)\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(total_loss.item())\n",
    "    print(f\"Step {step+1}/{NUM_STEPS} | Loss = {total_loss.item():.6f} | JEPA={loss_dict['JEPA'].item():.6f} VICReg={loss_dict['VICReg'].item():.6f} Drift={loss_dict['Drift'].item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a7c30",
   "metadata": {},
   "source": [
    "8. Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a35c1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), ckpt_path)\n",
    "print(f\"Checkpoint saved at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b2528",
   "metadata": {},
   "source": [
    "9. Plot Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2be6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss on Tokenized BEV Dataset\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a28deb9",
   "metadata": {},
   "source": [
    "10. Inference & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25943b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sample_frames, sample_kin = next(iter(loader))\n",
    "sample_frames, sample_kin = sample_frames.to(DEVICE), sample_kin.to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_tokens, _, _ = model(sample_frames, sample_kin)\n",
    "\n",
    "# Unpatchify tokens to images\n",
    "B, N, D = pred_tokens.shape\n",
    "ph = pw = int(N ** 0.5)\n",
    "pred_imgs = unpatchify(pred_tokens.cpu(), ph, pw, patch_size=PATCH_SIZE)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(min(4, B)):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(pred_imgs[i].permute(1,2,0))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
